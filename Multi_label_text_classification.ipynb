{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aliejabbari/multi_label_text_classification/blob/main/Multi_label_text_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bij91pNWQOR5"
      },
      "source": [
        "# Multi-label text classification\n",
        "**Author:** [Farrokh Karimi](https://github.com/farrokhkarimi)\n",
        "\n",
        "**Editor:** [Ali Jabbari](https://github.com/aliejabbari)\n",
        "\n",
        "**Description:** In this notebook, we want to improve our model to have better accuracy in classifying new data in multi-label text classification task.\n",
        "I tested different Deeplearning Networks architecture to test which one gives better results on this data set and came up with the following answer with simple network architecture.\n",
        "I obtained accuracy of 84.25, 83.11 and 82.16 from the model using network with dense architecture, deep network with block transformer and deep network with convolutional layer. In all three cases, the accuracy obtained is better than the sample made by the author."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import important laibrary**"
      ],
      "metadata": {
        "id": "WtoYw5HZkdDN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "sL739kMAEsU9"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import tensorflow as tf\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Download and Read Runash Dataset**\n"
      ],
      "metadata": {
        "id": "AW3Als2NlDCl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SHa9m3aLEbyP",
        "outputId": "bfbc07d1-d42d-4eb0-8c9f-a363df04958b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Yq3XTnACkvaIiNlhX09Zth55nOau7jQy\n",
            "To: /content/Ronash_DS_Assignment.csv\n",
            "\r  0% 0.00/1.05M [00:00<?, ?B/s]\r100% 1.05M/1.05M [00:00<00:00, 31.6MB/s]\n"
          ]
        }
      ],
      "source": [
        "# downloading Data from the Google Drive link\n",
        "!gdown 1Yq3XTnACkvaIiNlhX09Zth55nOau7jQy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6QpBuoWrC5QS",
        "outputId": "d00bcd7a-2118-4c7b-b9a6-16cdcc062a3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ronash_DS_Assignment.csv  \u001b[0m\u001b[01;34msample_data\u001b[0m/\n"
          ]
        }
      ],
      "source": [
        "ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        },
        "id": "722bMOmzF4_H",
        "outputId": "ad4845ce-3cb0-4b41-d890-d8fac221a3a0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         product_id                                              title  \\\n",
              "0     3937721221199    Fidele Super Premium Adult Large Breed Dog Food   \n",
              "1     7353058033889                    Foldable Pet Toys Linen Storage   \n",
              "2     6594773549129                                     Bok Dok Diaper   \n",
              "3     4802008318014                              Tastybone Toy Chicken   \n",
              "4     1779705151539                Leather Leash Tab - Short Dog Leash   \n",
              "...             ...                                                ...   \n",
              "5265  4637089464407                              Candylab MOO Milk Van   \n",
              "5266  4996632444987  Truck - Modern Era Vehicles -- Red, White -  S...   \n",
              "5267  5528541003927  Car Sticker Flags Decal American Flag Sticker for   \n",
              "5268  1395163889730          Lazer Helmets Bayamo Pit Bull - Full Face   \n",
              "5269  3535679324240                             Deutz Agrotron Tractor   \n",
              "\n",
              "                 vendor                                               tags  \\\n",
              "0                Fidele  ['Adult', 'Bangalore', 'Chennai', 'Chicken', '...   \n",
              "1             Cap Point                                                 []   \n",
              "2             Pets Home  ['Brand_Pet Arabia', 'Category_Pets Home', 'Ca...   \n",
              "3             TastyBone                                                 []   \n",
              "4            Mighty Paw                 ['Leash', 'Leash Tab', 'Training']   \n",
              "...                 ...                                                ...   \n",
              "5265           Candylab  ['3 Years +', 'candylab', 'Discount Products',...   \n",
              "5266   Woodland Scenics  ['HO Scale', 'ho-scale-items', 'vehicles', 'wo...   \n",
              "5267        Cyan Selene                                          ['Other']   \n",
              "5268  OPEN BOX BARGAINS  ['65061090', 'Antiscratch Pinlock Ready Visor'...   \n",
              "5269               Siku  ['$0 to $25', 'diecast-models', 'gift-finder',...   \n",
              "\n",
              "                    category  \n",
              "0     Animals & Pet Supplies  \n",
              "1     Animals & Pet Supplies  \n",
              "2     Animals & Pet Supplies  \n",
              "3     Animals & Pet Supplies  \n",
              "4     Animals & Pet Supplies  \n",
              "...                      ...  \n",
              "5265        Vehicles & Parts  \n",
              "5266        Vehicles & Parts  \n",
              "5267        Vehicles & Parts  \n",
              "5268        Vehicles & Parts  \n",
              "5269        Vehicles & Parts  \n",
              "\n",
              "[5270 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-14cb7eb4-1f1d-473b-ada3-46dd244484e0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>product_id</th>\n",
              "      <th>title</th>\n",
              "      <th>vendor</th>\n",
              "      <th>tags</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3937721221199</td>\n",
              "      <td>Fidele Super Premium Adult Large Breed Dog Food</td>\n",
              "      <td>Fidele</td>\n",
              "      <td>['Adult', 'Bangalore', 'Chennai', 'Chicken', '...</td>\n",
              "      <td>Animals &amp; Pet Supplies</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7353058033889</td>\n",
              "      <td>Foldable Pet Toys Linen Storage</td>\n",
              "      <td>Cap Point</td>\n",
              "      <td>[]</td>\n",
              "      <td>Animals &amp; Pet Supplies</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6594773549129</td>\n",
              "      <td>Bok Dok Diaper</td>\n",
              "      <td>Pets Home</td>\n",
              "      <td>['Brand_Pet Arabia', 'Category_Pets Home', 'Ca...</td>\n",
              "      <td>Animals &amp; Pet Supplies</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4802008318014</td>\n",
              "      <td>Tastybone Toy Chicken</td>\n",
              "      <td>TastyBone</td>\n",
              "      <td>[]</td>\n",
              "      <td>Animals &amp; Pet Supplies</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1779705151539</td>\n",
              "      <td>Leather Leash Tab - Short Dog Leash</td>\n",
              "      <td>Mighty Paw</td>\n",
              "      <td>['Leash', 'Leash Tab', 'Training']</td>\n",
              "      <td>Animals &amp; Pet Supplies</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5265</th>\n",
              "      <td>4637089464407</td>\n",
              "      <td>Candylab MOO Milk Van</td>\n",
              "      <td>Candylab</td>\n",
              "      <td>['3 Years +', 'candylab', 'Discount Products',...</td>\n",
              "      <td>Vehicles &amp; Parts</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5266</th>\n",
              "      <td>4996632444987</td>\n",
              "      <td>Truck - Modern Era Vehicles -- Red, White -  S...</td>\n",
              "      <td>Woodland Scenics</td>\n",
              "      <td>['HO Scale', 'ho-scale-items', 'vehicles', 'wo...</td>\n",
              "      <td>Vehicles &amp; Parts</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5267</th>\n",
              "      <td>5528541003927</td>\n",
              "      <td>Car Sticker Flags Decal American Flag Sticker for</td>\n",
              "      <td>Cyan Selene</td>\n",
              "      <td>['Other']</td>\n",
              "      <td>Vehicles &amp; Parts</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5268</th>\n",
              "      <td>1395163889730</td>\n",
              "      <td>Lazer Helmets Bayamo Pit Bull - Full Face</td>\n",
              "      <td>OPEN BOX BARGAINS</td>\n",
              "      <td>['65061090', 'Antiscratch Pinlock Ready Visor'...</td>\n",
              "      <td>Vehicles &amp; Parts</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5269</th>\n",
              "      <td>3535679324240</td>\n",
              "      <td>Deutz Agrotron Tractor</td>\n",
              "      <td>Siku</td>\n",
              "      <td>['$0 to $25', 'diecast-models', 'gift-finder',...</td>\n",
              "      <td>Vehicles &amp; Parts</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5270 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-14cb7eb4-1f1d-473b-ada3-46dd244484e0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-14cb7eb4-1f1d-473b-ada3-46dd244484e0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-14cb7eb4-1f1d-473b-ada3-46dd244484e0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# reading the csv file as a dataframe\n",
        "df = pd.read_csv('Ronash_DS_Assignment.csv')\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data prerpocessing**"
      ],
      "metadata": {
        "id": "-_A85TiKlRr4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6E1ZDXyPlr6y",
        "outputId": "f114d171-3987-4f10-a82a-c761a6366ac7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Apparel & Accessories        1000\n",
              "Animals & Pet Supplies        500\n",
              "Food, Beverages & Tobacco     400\n",
              "Sporting Goods                400\n",
              "Luggage & Bags                400\n",
              "Home & Garden                 400\n",
              "Health & Beauty               400\n",
              "Media                         300\n",
              "Toys & Games                  300\n",
              "Furniture                     200\n",
              "Baby & Toddler                200\n",
              "Arts & Entertainment          200\n",
              "Electronics                   100\n",
              "Business & Industrial         100\n",
              "Office Supplies               100\n",
              "Vehicles & Parts              100\n",
              "Hardware                       50\n",
              "Cameras & Optics               50\n",
              "Software                       50\n",
              "Religious & Ceremonial         20\n",
              "Name: category, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# counting the number of each label\n",
        "df['category'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Un_ggKoLUAEf",
        "outputId": "1c3fd904-f09a-4cbc-d70b-6c7f76272ead"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 0 duplicate title.\n",
            "There are 1256 duplicate vondor.\n",
            "There are 716 duplicate tags.\n"
          ]
        }
      ],
      "source": [
        "# counting how many indices are duplicated in each column\n",
        "print(f\"There are {sum(df['title'].duplicated())} duplicate title.\")\n",
        "print(f\"There are {sum(df['vendor'].duplicated())} duplicate vondor.\")\n",
        "print(f\"There are {sum(df['tags'].duplicated())} duplicate tags.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VD95efZwCRYT",
        "outputId": "9a292b68-89f3-4be8-da77-a9b4d8c29be5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# counting the number of Nan samples\n",
        "df.isnull().values.sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhPJQuDEb8oN"
      },
      "source": [
        "There are just 3 Nan samples in the dataset so we can ignore them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aH9UzP7-__P2",
        "outputId": "430b1e29-38b1-4ea1-cf39-c9dcdb48cb2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fidele super premium adult large breed dog food fidele adult bangalore chennai chicken doberman dog dry foods fidele german shepherd golden retriever great dane highpriority imported labrador less than 1000 less than 2000 less than 500 mastiff orange pet nutrition \n",
            "foldable pet toys linen storage cap point \n",
            "bok dok diaper pets home brand pet arabia category pets home category small pets supplies type pet home type pet supplies \n",
            "tastybone toy chicken tastybone \n",
            "leather leash tab short dog leash mighty paw leash leash tab training \n",
            "pridebites texas guitar dog toy pride bites brand pridebites toy type plush \n",
            "burns sensitive pork potato burns 10 25 25 50 50 75 adult burns coat dog food food delivery jansale18 natural nonsale19 sensitive size 12kg size 2kg size 6kg skin \n",
            "bully sticks dog toy adog.co bully sticks dog chew toys dog toys \n",
            "kazoo tough giraffe dog toy kazoo brand kazoo june2021 kazoo material plush plush \n",
            "orgo dog biscuits fresh milk petku brand orgo category dogs dogs lifestage all lifestages orgo price rp 0 to rp 100.000 subcategory treats treats \n"
          ]
        }
      ],
      "source": [
        "# the function for extracting and standardizing the sentences\n",
        "def text_extraction(dfi):\n",
        "  # in this function, we concatenate text feature parts of the data as a sentence\n",
        "  sentence = ' '.join([dfi['title'], str(dfi['vendor']), dfi['tags']])\n",
        "  # Remove punctuations\n",
        "  sentence = re.sub('[^a-zA-Z0-9$.]', ' ', sentence)\n",
        "  # Single character removal\n",
        "  sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sentence)\n",
        "  # Removing multiple spaces\n",
        "  sentence = re.sub(r'\\s+', ' ', sentence)\n",
        "  # Changint to lowercase\n",
        "  sentence = sentence.lower()\n",
        "  return sentence\n",
        "\n",
        "# printing 10 sample sentences\n",
        "for i in range(10):\n",
        "  print(text_extraction(df.iloc[i]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "7x4WG7NC9Xz3",
        "outputId": "03025fc2-c0e2-4ceb-af63-4733cc58c6b8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   text  \\\n",
              "0     fidele super premium adult large breed dog foo...   \n",
              "1            foldable pet toys linen storage cap point    \n",
              "2     bok dok diaper pets home brand pet arabia cate...   \n",
              "3                      tastybone toy chicken tastybone    \n",
              "4     leather leash tab short dog leash mighty paw l...   \n",
              "...                                                 ...   \n",
              "5265  candylab moo milk van candylab 3 years candyla...   \n",
              "5266  truck modern era vehicles red white scale ho w...   \n",
              "5267  car sticker flags decal american flag sticker ...   \n",
              "5268  lazer helmets bayamo pit bull full face open b...   \n",
              "5269  deutz agrotron tractor siku $0 to $25 diecast ...   \n",
              "\n",
              "                       label  label_int  \n",
              "0     Animals & Pet Supplies          0  \n",
              "1     Animals & Pet Supplies          0  \n",
              "2     Animals & Pet Supplies          0  \n",
              "3     Animals & Pet Supplies          0  \n",
              "4     Animals & Pet Supplies          0  \n",
              "...                      ...        ...  \n",
              "5265        Vehicles & Parts         19  \n",
              "5266        Vehicles & Parts         19  \n",
              "5267        Vehicles & Parts         19  \n",
              "5268        Vehicles & Parts         19  \n",
              "5269        Vehicles & Parts         19  \n",
              "\n",
              "[5270 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bf2d589a-d655-4411-b2a8-3c47d82b6f8b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>label_int</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>fidele super premium adult large breed dog foo...</td>\n",
              "      <td>Animals &amp; Pet Supplies</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>foldable pet toys linen storage cap point</td>\n",
              "      <td>Animals &amp; Pet Supplies</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>bok dok diaper pets home brand pet arabia cate...</td>\n",
              "      <td>Animals &amp; Pet Supplies</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>tastybone toy chicken tastybone</td>\n",
              "      <td>Animals &amp; Pet Supplies</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>leather leash tab short dog leash mighty paw l...</td>\n",
              "      <td>Animals &amp; Pet Supplies</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5265</th>\n",
              "      <td>candylab moo milk van candylab 3 years candyla...</td>\n",
              "      <td>Vehicles &amp; Parts</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5266</th>\n",
              "      <td>truck modern era vehicles red white scale ho w...</td>\n",
              "      <td>Vehicles &amp; Parts</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5267</th>\n",
              "      <td>car sticker flags decal american flag sticker ...</td>\n",
              "      <td>Vehicles &amp; Parts</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5268</th>\n",
              "      <td>lazer helmets bayamo pit bull full face open b...</td>\n",
              "      <td>Vehicles &amp; Parts</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5269</th>\n",
              "      <td>deutz agrotron tractor siku $0 to $25 diecast ...</td>\n",
              "      <td>Vehicles &amp; Parts</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5270 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bf2d589a-d655-4411-b2a8-3c47d82b6f8b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bf2d589a-d655-4411-b2a8-3c47d82b6f8b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bf2d589a-d655-4411-b2a8-3c47d82b6f8b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# creating the dataset\n",
        "dataset = pd.DataFrame(columns=['text', 'label'])\n",
        "for i in range(len(df)):\n",
        "  dataset = dataset.append({'text':text_extraction(df.iloc[i]), 'label':df.iloc[i]['category']}, ignore_index = True)\n",
        "\n",
        "# creating integer labels for multiclass training\n",
        "dataset['label_int'] = pd.Categorical(dataset['label']).codes\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9uHdTY3p9Xfr",
        "outputId": "d6c6a8fc-5bf6-4181-ec41-453380e9edd8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Animals & Pet Supplies',\n",
              " 'Apparel & Accessories',\n",
              " 'Arts & Entertainment',\n",
              " 'Baby & Toddler',\n",
              " 'Business & Industrial',\n",
              " 'Cameras & Optics',\n",
              " 'Electronics',\n",
              " 'Food, Beverages & Tobacco',\n",
              " 'Furniture',\n",
              " 'Hardware',\n",
              " 'Health & Beauty',\n",
              " 'Home & Garden',\n",
              " 'Luggage & Bags',\n",
              " 'Media',\n",
              " 'Office Supplies',\n",
              " 'Religious & Ceremonial',\n",
              " 'Software',\n",
              " 'Sporting Goods',\n",
              " 'Toys & Games',\n",
              " 'Vehicles & Parts']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# extracting the names of the labels\n",
        "labels_names = list(Counter(dataset['label']).keys())\n",
        "labels_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXCgd6QTC_k6",
        "outputId": "a2f0f064-f449-4793-f4af-e0582d09bbd7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label 0 corresponds to Animals & Pet Supplies\n",
            "Label 1 corresponds to Apparel & Accessories\n",
            "Label 2 corresponds to Arts & Entertainment\n",
            "Label 3 corresponds to Baby & Toddler\n",
            "Label 4 corresponds to Business & Industrial\n",
            "Label 5 corresponds to Cameras & Optics\n",
            "Label 6 corresponds to Electronics\n",
            "Label 7 corresponds to Food, Beverages & Tobacco\n",
            "Label 8 corresponds to Furniture\n",
            "Label 9 corresponds to Hardware\n",
            "Label 10 corresponds to Health & Beauty\n",
            "Label 11 corresponds to Home & Garden\n",
            "Label 12 corresponds to Luggage & Bags\n",
            "Label 13 corresponds to Media\n",
            "Label 14 corresponds to Office Supplies\n",
            "Label 15 corresponds to Religious & Ceremonial\n",
            "Label 16 corresponds to Software\n",
            "Label 17 corresponds to Sporting Goods\n",
            "Label 18 corresponds to Toys & Games\n",
            "Label 19 corresponds to Vehicles & Parts\n"
          ]
        }
      ],
      "source": [
        "# printing each integer label and its corresponding name label\n",
        "for i, label in enumerate(labels_names):\n",
        "  print(\"Label\", i, \"corresponds to\", label)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creat train_df and test_df from train test split**"
      ],
      "metadata": {
        "id": "vsZMwhhsl4CU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bWd2Rfp69X8g",
        "outputId": "32dff856-7480-4f5d-d662-7ec44b003ab5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples in training set: 4216\n",
            "Number of samples in validation set: 527\n",
            "Number of samples in test set: 527\n"
          ]
        }
      ],
      "source": [
        "# splitting dataset to train, validation, and test dataframes\n",
        "train_df, test_df= train_test_split(dataset, test_size=0.2, random_state=42)\n",
        "val_df = test_df.sample(frac=0.5)\n",
        "test_df.drop(val_df.index, inplace=True)\n",
        "\n",
        "print(f\"Number of samples in training set: {len(train_df)}\")\n",
        "print(f\"Number of samples in validation set: {len(val_df)}\")\n",
        "print(f\"Number of samples in test set: {len(test_df)}\")\n",
        "\n",
        "# extracting texts and labels from dataframes\n",
        "train_texts = train_df['text']\n",
        "train_labels = train_df['label_int']\n",
        "val_texts = val_df['text']\n",
        "val_labels = val_df['label_int']\n",
        "test_texts = test_df['text']\n",
        "test_labels = test_df['label_int']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C4kA4X60zkC3",
        "outputId": "2f3344c6-3b23-4a8b-b92a-1b095e85ce21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Texts: [b'housie tambola game by brands with foldable reusable tickets snooplay 13 17 year olds 18 years above 251 500 8 12 year olds age no bar all time favourite below 1000 below 400 below 500 best selling board games creative games gifts customer favourites diwali family friends night family games friends family nights geek gifts for boys gifts for friends gifts for girls gifts for kids gifts for parents googleshopping nerd or geek new new collection outdoor games party accessories party essentials party freak party games party games for grown ups party games for kids premium unique new toys '\n",
            " b'foldable waterproof raised dog bed dogiti '\n",
            " b'quadrello di bufala cheese cut wrapped by igourmet category cheese cut cheeses milk type buffalo nutrition full set origin italy shipping perishable texture semi soft type stinky and washed rind wholesale cheese collection '\n",
            " b'quay vip pink navy to pink lens quay accessories new summer sunglasses '\n",
            " b'seachem multitest ammonia seachem '\n",
            " b'smart electric cat teasing toy pet clever cat toys cats rr track catproducts rr track cattoys '\n",
            " b'petroleum mixture sign the sign shed black text chemical chemical signs flammable signs general hazard portrait yellow bg '\n",
            " b'scott kingery andrew mccutchen philadelphia phillies ring the bell dual bobblehead foco data athlete andrew mccutchen data athlete scott kingery data city philadelphia data edition exclusive data filter collection no data filter discount yes data league mlb data region pennsylvania data sub category1 bobbleheads data team philadelphia phillies '\n",
            " b'diy personalised dreamcatcher activity kit sea animal doxbox store '\n",
            " b'dainty corduroy bow in lilac sweet first love bow corduroy headband purple spo disabled wos '\n",
            " b'new bts stylish backpack the pocket store '\n",
            " b'planet bike big buck fat front planet bike bicycle fenders bike accessories bikes fenders front fenders full price planet bike unisex '\n",
            " b'ms. better trans canada bitters enterprises jesemi inc. betters canada ms trans '\n",
            " b'drawstring backpack pink zig zag yoobi 10 15 2020 primedaydeal accessories all bags flair back to school backpacks bags bf2019 book bag book bags bookbag bookbags newyear pink pink zig zag sale summer2020 supplybundle zig zags '\n",
            " b'pineapple mini food speaker magnum brands add on birthday gift girl music pos speaker '\n",
            " b'interactive iq treat ball toy for dogs cats cj feeder waterer pet supplies '\n",
            " b'whisper of lord ganesha tarot deck u.s. games '\n",
            " b'handcrafted aasha cuff bracelet colorful cuff bracelet made with wooden beads wrapped with recycled sari fabrics. aasha bracelet comfy fair trade handcrafted handmade jewelry '\n",
            " b'idrop belik facial anti aging wrinkle ultrasonic face massager toothbrush attachment idrop anti aging anti wrinkle electric massager face massage facial massager health health beauty health fitness health care healthcare healthy healthy massager massage massager new ultrasonic '\n",
            " b'wood nativity puzzle mud pie one coas 10760023 baby children christmas gift god jesus kid religion toy '\n",
            " b'p.l.a.y. zoomierex fantastug sea foam dog toy p.l.a.y. brand p.l.a.y. summer collection toy type fetch toy type floating toy type rubber toy type tug twr '\n",
            " b'wallis simpson signed autobiography paul fraser collectibles autographs '\n",
            " b'imperial earring daya jewelry brass flower gold imperial spo default spo disabled spo enabled star tribal '\n",
            " b'armadillo nest charcoal armadillo alfresco armadillo door mats down to earth floor homeware homeware rugs mats labour weekend living modern boho rug rugs mats '\n",
            " b'millie pillow foreside pillows textiles '\n",
            " b'jelly brush aprilskin.us all '\n",
            " b'alarm you re little bitch blue blue blue crew cute exclude feed agegroup adult feed cl0 regularprice womens sassy funny words inappropriate cute profanity swear words exclude rude crude feed color blue feed cond new feed gender feed gender female feed gpc 209 funny inappropriate print profanity red regularprice rude crude sassy socks swear words womens words '\n",
            " b'boutique de paris lashes4today glamorous lashes luxury '\n",
            " b'dog pakiet dnp pc skin support pick me pets brand dolina noteci category pet supplies type dog food '\n",
            " b'plaza weekend diaper bag 7am label final sale addswatchrow adult age adult category diaper bags category weekenders color black color grey diaper diaper diaper ba dipper style plaza bag voyage '\n",
            " b'water sterling silver necklace wear the peace 925 sterling silver all products necklaces new arrivals '\n",
            " b'bain ultra violet rastase adha2020 adjusted assaad back in stock items bahaa black friday 2020 enabled blond absolu blondabsolu ramadan21 btpcat main 132768825422 btpcat other 132768825422 elian dada fadia el mendelek for colored blond hair hair care haircare summerfiesta sale jan 4 2021 price increase july 28th updated july increase ker aprist1st 2021 increase ker august 2021 price increase ker march 1st 2021 price increase ker priceincrease june1st 2021 kerastase ramadan21 rastase loolia2y mahmoud al zarif michel zeytoun non solar october 1st 2020 price increase or or reviews ppd price decrease 16th september 2021 ppd price decrease sept 2021 ppd price increase october1st 2021 ppd pricedecrease midseptember2021 ppd priceincrease 12th october 2021 price updated shampoos shant tawetian shop all stockcount 31 03 2021 weekend summerfiesta sale '\n",
            " b'braided bone orange tall tails brand tall tails pet dogs price $20.00 $29.99 type interactive toys '\n",
            " b'police digital cuddle blue line lincoln lexi fabric sale fabric '\n",
            " b'the bystander dvd cchf children dvd dvd childrens ntbita '\n",
            " b'men canvas tri fold short wallet coin holder card holder textured wallet bg men bags wallets '\n",
            " b'ndur mini cookware kit alcohol burner proforce equipment alcohol stove bushcraft cooking kit bushcraft cookware camp cooking kit camp cookware cook kit cook set cooking pot cookware survival cooking survival cooking kit survival cookware '\n",
            " b'indoor silent stationary spinning bike clearance private label age group null brand private label category cardio category cardio machines category exercise fitness category exercise bikes category sporting goods color condition new open box return config automatic warranties config clearance discount gender is bundle false multipack 0 nav category sporting goods exercise fitness cardio cardio machines exercise bikes nav clearance nav first cat sporting goods nav last chance no po box over 100 pattern size warranty 30 days '\n",
            " b'ken ultra premium egg yolk flake ken fish food flake food kens kens ultra '\n",
            " b'tillak soto regulator stove pouch shella cup storage case durable and water resistant cordura fabric compatible with iwatani junior compact burners black goods of japan camp kitchen '\n",
            " b'ic berlin thomas a. men eyeglasses ic berlin eyeglasses ic berlin men eyeglasses '\n",
            " b'assam silk feel maroon colour digital village print fabric 2222 assam silk feel prints attribute set name migration fabric base unit cm base unit min 100 by prints types by silk premium category by prints types category by prints types design category by prints types design village category by prints types prints category by prints types prints silk prints category by prints types type category by prints types type digital category by silk premium category by silk premium premium prints category by silk premium premium prints assam silk feel prints colour maroon design digital dimension width 1.12 meter 44 inches display colour maroon display unit meter ex pdm fabric weight light weight gender women generic name fabric googleproductcategory apparel accessories clothing gst inclusive 5 id 2222 lining suggested yes material assam silk feel mm1 maroon fabrics maroon shades tones new root category occassion festival social events premium prints prints product hsn code 520811 quality pure silk prints sold by length type type digital type printed unit meter usage anarkali usage blouse usage crop top usage female shirt usage kimono shirt usage kurta usage kurti usage palazzo usage saree usage saree pallu usage skirt usage top usage tunic village washing care gentle wash in cold water width 1.12 meter 44 inches '\n",
            " b'burgundy miniature backpack mostafa hanafy all backpack mini backpacks new arrivals sale '\n",
            " b'otay toque black kriscollins black otay pre order swatch navy otay toque navy swatch royalblue otay toque royal '\n",
            " b'dukes county international cricket ball dukes brand dukes brand dukes '\n",
            " b'instant foot spa spray amazing lola foot health health beauty instant spa spray '\n",
            " b'fleece midlayer top simms fall 19 fishing fishing clothing fishing ls shirts locally simms orange unisex '\n",
            " b'horseshoe bit serving tray vagabond house 1 10 2011 equestrian equestrian 1 feed cl0 equestrian setof1 trays vagabond house '\n",
            " b'custom match point volleyball baden sports any indoor outdoor machine stitched official synthetic leather '\n",
            " b'soft book teether set petit collage soft book soft toy wooden '\n",
            " b'tantrik sambhog aur samadhi empty canvas books book contemporary fiction hindi paperback penguin random house spreadr hidden unedit '\n",
            " b'microsoft filler license open license microsoft '\n",
            " b'nfl rico industries bling chrome license plate frame with glitter accent new... rico industries 12.25 inches accent afco afco au afco aub00j10lv9o bling chrome color fcgl1401 featured from research featured item frame giants glitter industries license new nfl plate price 20 rico ship to us team with york '\n",
            " b'sunrise bow tie puccissime pet couture handmade dog accessories luxury dog products pet supplies '\n",
            " b'cape verde framed canvas iluka road category art category clearance category decor category paintings free freight latest item range contemporary furniture '\n",
            " b'various small books referencing various small books by ed ruscha lacma store '\n",
            " b'smartykat tassel and ball thwapper teaser cat toy smartykat adult cat toys catnip toys flitz green less than 1000 less than 2000 less than 500 marketing smartykat '\n",
            " b'gouguenheim sparkling malbec ros mutual distributing argentina easter 21 malbec rose sparkling summer2020 '\n",
            " b'magical symbols alphabets by sandra kynes skull barrel co. bmagsym books mystical books paperback books symbology books '\n",
            " b'no orange blue shampoo or mask fanola concerns brass favorites hair style balayage babylights ombre highlights hair type coily curly straight wavy thick fine virgin brunette ingredients cruelty free shampoo type shampoo '\n",
            " b'stamped silver hair forks tiffany stone dendritic opal jasper or lace agate la femme boheme hair fork ooak ready to ship '\n",
            " b'north fork ripstop series alpine division duffle grey jetti '\n",
            " b'modernist pencil set rifle paper co. non sale '\n",
            " b'comfortable donut cuddler round dog bed dogiti '\n",
            " b'cheesy jalape popcorn jody popcorn bags cheesy jalapeno flavor savory savory size bag '\n",
            " b'lettia memory foam clik all purpose girth lettia dropship union girths horse new tack '\n",
            " b'saltygirl beauty multi stick melissa saltygirl beauty '\n",
            " b'bommalata hathi earrings zola accessories bharmiben jeevan fashion earrings fashion jewelry hand wash jewellery jewelry under 1500 necklace rs.501 rs.1000 zola '\n",
            " b'gemma nutella wedge bootie cecelia boots booties cecelia wedges '\n",
            " b'cat laser toys 8blue automatic cat laser toy cat laser toy haley interactive laser cat toy '\n",
            " b'oligarch vodka oligarch category spirits oligarch region russia size 750ml vodka '\n",
            " b'amelia dome ring kinn anniversary sale 10.21 diamond collection dome ring eligible for discount faire gemstone herringbone collection holiday 2021 kinn classics ring '\n",
            " b'leopard hoodie dog sweater dogo brown dog sweaters dogo m under $100 under $150 under $200 under $250 under $50 under $75 xl xs xxl xxs '\n",
            " b'island mimosa body wash hand in hand soap no dropship '\n",
            " b'bravado designs plunge nursing bra antique white bravado designs hospital mama new mom price hk$401 hk$500 product type hands free pumping product type pumping bra '\n",
            " b'shopping bag tote pouch women travel storage handbag shoulder bag stripes canvas shopping bags bg handbags women bags '\n",
            " b'charcoal bedford felt backpack graf lantz back to felt backpack charcoal family bedford gender womens jetti material felt normal shipping 2 3 weeks the accessories edit waitlist ygroup bedfordbackpackfelt '\n",
            " b'green plant bronx flower delivery add plants size '\n",
            " b'wtn rotting in pestilence cd album nm or leora colby album cd death metal grindcore rock '\n",
            " b'aurelia ladies technical riding jacket premier equine int. collection ladies waterproof riding coats jackets gilets collection equestrian clothing collection ladies riding fleeces hoodies colour blue colour grey hs2code 6202930000 hs2codeus 6202.93.0911 icon breathable icon ykk zip sizeguide jackets gilets6up tradepriceexvat 2200 tradepriceincvat 2640 '\n",
            " b'tribeca ottoman charcoal with dark base medium darcy and duke category chairs and seating category furniture category ottomans and footstools latest item range contemporary furniture range manhattan apartment '\n",
            " b'rumi pants army lozyhijab bahan cotton color green kategori pants '\n",
            " b'urban color love me matte lipcolor exotic tangerine kk beauty beauty product lip colour makeup matte modicare urban color women worldshopon '\n",
            " b'royal princess pink wooden dresser toy with make up set my aashis furniture kids furniture kids playroom furniture '\n",
            " b'end cap billet grooved chrome for harley davidson supertrapp custom chrome escapes harley davidson '\n",
            " b'yoke dress virgo lilac oliphantdesign dresses favorite things featured collection size xl size xxs ss2021 vacation women '\n",
            " b'astronaut jellyfish wall hanging tapestry minideals store astronaut jellyfish space tapestry wall hanging '\n",
            " b'pioneer children sang as they walked marvin goldstein single cedar fort publishing media '\n",
            " b'sphero ultimate lightning mcqueen sphero mob remote sphero '\n",
            " b'shibari you can use more shibari you can use two book set the twisted monk books intermediate starting out '\n",
            " b'kitsu earrings sunflower hoops kitsu '\n",
            " b'waterproof triangle bike bicycle bag cycling front bag bicycle pouch frame bags bicycle accessories not include water bottle nz outdoors '\n",
            " b'banarasee brocade fabric with zari resham jaal blue banarasee art silk blue '\n",
            " b'gorsedd dining table acme furniture dining room dining table home '\n",
            " b'keepcup ly th tinh gi nhi longplay banksia keepcup clear edition keepcup longplay banksia 16oz mugs reuseable cup '\n",
            " b'mirage created emerald and black diamond set stud earrings in sterling silver bevilles buying for her category earrings department diamond diamond clarity i2 3 diamond colour i discount product earring style stud eligible for last chance discount eligible for last wow club eligible for new member discount fastdelivery gemstone diamond gemstone emerald metal sterling silver mirage personality traditional sku 9s19001 skuadded spend and save vipprice wgproducts '\n",
            " b'elizabeth sand indoor outdoor rug dash and albert beige rug beige rugs brown dash albert dash and albert dropship geometric geometric rug geometric rugs indoor ivory ivory rug ivory rugs khaki rug khaki rugs mc rugs neutral neutral rug neutral rugs outdoor outdoor rug outdoor rugs rug sand '\n",
            " b'chelsea casual suede top boots jonally boots shoes '\n",
            " b'easyrest microplush quilt easyrest bedding quilts duvets easyrest microfibre size double size single summer '\n",
            " b'becca cosmetics liquid light highlight kit becca cosmetics becca cosmetics cosmetics gift bar gifts gifts palettes holiday holiday sets lip gloss '\n",
            " b'aquatopia led air volcano aquatopia '\n",
            " b'oliver goldsmith cole oliver goldsmith acetate men progressive friendly rectangular rx lens suitable 200 to 400 '\n",
            " b'dpa fine single ear wireless headset microphone rental beige dpa corporate event rentals lavalier mic microphone rentals seminar conference '\n",
            " b'heartbreaking dawns jalape pineapple heartbreaking dawns all fruit based citrus fruit based gluten free habanero heartbreaking dawns jalapeno lime mild pineapple '\n",
            " b'chloe crystal clutch chloe bag bead beads bejeweled black black gold black white chain chloe chloe clutch chloe crystal clutch cloe club clubbing clutch couture cross body crossbody crystal crystal clutch crystals elegance elegant evening evening wear favorite feminine girl girls girly glitter glittery glitz gold golden handbag jewels leather luxurious luxury new years nye party pearl pearls purse shoulder bag silver sophisticated sophistication strap synthetic leather tassel tassels zipped zipper '\n",
            " b'naisha at the museum bibliophiles 12 18 months 18 24 months 24 months bibliophiles others paperback picture books '\n",
            " b'rubber tire chew toy chetitay official store dog pet toy '\n",
            " b'b swiss wisdom star bb face spoon set swiss brand h swiss avg profit 20 avg profit percent 40 h swiss baby items baby items dahsing level 1 baby toddler not brandsdis not on sale not regular priced optimise 8off overseas ads price quote '\n",
            " b'craig portable power bank with dual usb charging port craig '\n",
            " b'oriflamme ablaze pre order studio availability pre order newproduct product type board games '\n",
            " b'callum short navy blazer diesel mens shorts ss22 '\n",
            " b'led safety blinkers knuckle lights '\n",
            " b'baozi shearling span t.di.moro dark grey span elleme baozi '\n",
            " b'neutral stripe contemporary rug modernica props contemporary grey wool '\n",
            " b'aviation movie creators pack alan walker store asia all digital '\n",
            " b'women burton talent scout camber snowboard burton cf size 141 cf size 146 cf size 152 cf vendor burton '\n",
            " b'nevy lace front wig free part love for bling boutique '\n",
            " b'convertible leather briefcase backpack handmade world backpack book bag casual daypack crossbody bag ipad tablet bag knapsack laptop bag messenger bag satchel bag '\n",
            " b'profusion cosmetics highlight contour palette ii profusion cosmetics normal price '\n",
            " b'gaming chair with footrest green faux leather vidaxl 250 500 green ']\n",
            "labels: [18  0  7  1  0  0  4  2  0  1 12 17  7 12 18  0 15  1 10 18  0  2  1 11\n",
            "  2  9  1 10  0 12  1 10  0  3  6 12 11 17  0 17 10  2 12  1 17 10 17 17\n",
            " 17 18 13 16 17  0 11 13  0  7 13 10  1 12 14  0  7 17 10  1  1  0  7  1\n",
            "  0 10  3 12 12 11 13  1  8  1 10  8 19  1 11 13  6 13  1 17  2  8 11  1\n",
            " 11  1 11 10  0 10  6  7 12 13  0  3  6 18  1 17  1  2 16 17  1 12 10  8]\n"
          ]
        }
      ],
      "source": [
        "# creating data generators with batch size 32\n",
        "batch_size = 120\n",
        "raw_train_batch = tf.data.Dataset.from_tensor_slices((train_texts, train_labels)).batch(batch_size)\n",
        "raw_val_batch = tf.data.Dataset.from_tensor_slices((val_texts, val_labels)).batch(batch_size)\n",
        "raw_test_batch = tf.data.Dataset.from_tensor_slices((test_texts, test_labels)).batch(batch_size)\n",
        "\n",
        "# printing texts and labels of a batch of raw train\n",
        "for text, label in raw_train_batch.take(1):\n",
        "  print('Texts: {}'.format(text))\n",
        "  print('labels: {}'.format(label))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2QpUriFrsU_",
        "outputId": "54162f30-3fc5-485a-839f-5bc380bad5fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "112572\n"
          ]
        }
      ],
      "source": [
        "# counting how many words are there in the whole texts of the dataset\n",
        "num_of_words = 0\n",
        "for i in dataset['text']: num_of_words += len(i.split())\n",
        "print(num_of_words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfw3CqfZsWyT"
      },
      "source": [
        "There are about 112000 words in the texts.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ufQzaF9ncqZ",
        "outputId": "6bbe9002-ecfd-4e1e-9e5f-77712267041e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "309\n",
            "18933\n"
          ]
        }
      ],
      "source": [
        "# counting max sequence length and how many non-repetitive words are there in the whole texts of the dataset\n",
        "l = []\n",
        "max_seq_lenght = 0\n",
        "for i in dataset['text']:\n",
        "  lenght = len(i.split())\n",
        "  if lenght > max_seq_lenght: max_seq_lenght = lenght\n",
        "  for j in i.split():\n",
        "    if j not in l: l.append(j)\n",
        "\n",
        "print(max_seq_lenght)\n",
        "print(len(l))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGGf8rQorkSR"
      },
      "source": [
        "Maximum sequence length is 309 and There are about 19000 non-repetitive words in the whole dataset texts. So we set max word features to 10000 and sequence length to 350."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ey2QJjO97T9P",
        "outputId": "e2699a04-32d1-43dd-8099-fca80b708e23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Review tf.Tensor(b'housie tambola game by brands with foldable reusable tickets snooplay 13 17 year olds 18 years above 251 500 8 12 year olds age no bar all time favourite below 1000 below 400 below 500 best selling board games creative games gifts customer favourites diwali family friends night family games friends family nights geek gifts for boys gifts for friends gifts for girls gifts for kids gifts for parents googleshopping nerd or geek new new collection outdoor games party accessories party essentials party freak party games party games for grown ups party games for kids premium unique new toys ', shape=(), dtype=string)\n",
            "Label tf.Tensor(18, shape=(), dtype=int8)\n",
            "Vectorized text (<tf.Tensor: shape=(1, 309), dtype=int64, numpy=\n",
            "array([[12501,  9229,   192,    23,   343,    51,  1546,  2392,  9089,\n",
            "         9635,   740,  1609,   275,  2882,   372,    69,   959, 15878,\n",
            "          134,   109,    89,   275,  2882,    35,    55,   381,    16,\n",
            "          480,  7346,   783,   181,   783,   961,   783,   134,    79,\n",
            "         2792,   104,    57,  1195,    57,    53,  3072, 13287,  5047,\n",
            "          237,  1078,   716,   237,    57,  1078,   237,  6529,  4896,\n",
            "           53,    13,   334,    53,    13,  1078,    53,    13,   179,\n",
            "           53,    13,    62,    53,    13,  3473, 12859, 11174,   303,\n",
            "         4896,     3,     3,     8,   157,    57,   250,    17,   250,\n",
            "          316,   250,  7261,   250,    57,   250,    57,    13,  1904,\n",
            "         5674,   250,    57,    13,    62,   360,   632,     3,     6,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0]])>, <tf.Tensor: shape=(), dtype=int8, numpy=18>)\n"
          ]
        }
      ],
      "source": [
        "# setting the text vectorization layer with 10000 words and 350 sequence length\n",
        "max_features = 19000\n",
        "sequence_length = 309\n",
        "\n",
        "vectorize_layer = layers.TextVectorization(\n",
        "    max_tokens=max_features,\n",
        "    output_mode='int',\n",
        "    output_sequence_length=sequence_length)\n",
        "\n",
        "# fitting the state of the preprocessing layer to the train set. This will cause the model to build an index of strings to integers.\n",
        "vectorize_layer.adapt(train_texts)\n",
        "\n",
        "# defining the vectorize text function\n",
        "def vectorize_text(text, label):\n",
        "  text = tf.expand_dims(text, -1)\n",
        "  return vectorize_layer(text), label\n",
        "\n",
        "# retrieving a sample from a batch of texts and labels from the train set\n",
        "text_batch, label_batch = next(iter(raw_train_batch))\n",
        "first_review, first_label = text_batch[0], label_batch[0]\n",
        "print(\"Review\", first_review)\n",
        "print(\"Label\", first_label)\n",
        "print(\"Vectorized text\", vectorize_text(first_review, first_label))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X84dkB768GSx",
        "outputId": "61a695e3-bb25-493c-ad23-f820e707d0ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1401 --->  heel\n",
            " 313 --->  is\n",
            "Vocabulary size: 16230\n"
          ]
        }
      ],
      "source": [
        "# getting corresponding word of each integer \n",
        "print(\"1401 ---> \",vectorize_layer.get_vocabulary()[1401])\n",
        "print(\" 313 ---> \",vectorize_layer.get_vocabulary()[313])\n",
        "print('Vocabulary size: {}'.format(len(vectorize_layer.get_vocabulary())))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "DiW717GQ_77D"
      },
      "outputs": [],
      "source": [
        "# creating train, val, and test vectorized dataset and prefetching them\n",
        "train_ds = raw_train_batch.map(vectorize_text)\n",
        "val_ds = raw_val_batch.map(vectorize_text)\n",
        "test_ds = raw_test_batch.map(vectorize_text)\n",
        "\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Generating the model**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "At firs we generate a simple model with Embedding and GlobalAveragePooling1D and a dense.\n",
        "\n",
        "This is the best model with 84% accuracy "
      ],
      "metadata": {
        "id": "4LHRKwm8mPKT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "BBHmGG_SAWhp"
      },
      "outputs": [],
      "source": [
        "# model configuration\n",
        "embedding_dim = 256 #embeding_dim changed to 256 \n",
        "num_of_labels = 20\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "  layers.Embedding(max_features + 1, embedding_dim),\n",
        "  layers.Dropout(0.15),#dropout rate chenged to 0.15\n",
        "  layers.GlobalAveragePooling1D(),\n",
        "  layers.Dropout(0.20),#dropout rate chenged to 0.20\n",
        "  layers.Dense(num_of_labels)])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "uL6c-YGfAwLz"
      },
      "outputs": [],
      "source": [
        "# model compilation\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CIfmPA3SvX4d",
        "outputId": "b903820a-39bc-4873-936a-ed2947921d67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "36/36 [==============================] - 14s 258ms/step - loss: 2.9025 - accuracy: 0.1452 - val_loss: 2.8014 - val_accuracy: 0.2011\n",
            "Epoch 2/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 2.7236 - accuracy: 0.1881 - val_loss: 2.6946 - val_accuracy: 0.2011\n",
            "Epoch 3/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 2.6712 - accuracy: 0.1881 - val_loss: 2.6739 - val_accuracy: 0.2011\n",
            "Epoch 4/500\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 2.6585 - accuracy: 0.1881 - val_loss: 2.6630 - val_accuracy: 0.2011\n",
            "Epoch 5/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 2.6477 - accuracy: 0.1883 - val_loss: 2.6531 - val_accuracy: 0.2011\n",
            "Epoch 6/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 2.6373 - accuracy: 0.1883 - val_loss: 2.6435 - val_accuracy: 0.2011\n",
            "Epoch 7/500\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 2.6241 - accuracy: 0.1886 - val_loss: 2.6314 - val_accuracy: 0.2049\n",
            "Epoch 8/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 2.6084 - accuracy: 0.1890 - val_loss: 2.6177 - val_accuracy: 0.2049\n",
            "Epoch 9/500\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 2.5918 - accuracy: 0.1909 - val_loss: 2.6020 - val_accuracy: 0.2049\n",
            "Epoch 10/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 2.5716 - accuracy: 0.1921 - val_loss: 2.5838 - val_accuracy: 0.2049\n",
            "Epoch 11/500\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 2.5477 - accuracy: 0.2004 - val_loss: 2.5630 - val_accuracy: 0.2087\n",
            "Epoch 12/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 2.5214 - accuracy: 0.2073 - val_loss: 2.5394 - val_accuracy: 0.2144\n",
            "Epoch 13/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 2.4917 - accuracy: 0.2206 - val_loss: 2.5130 - val_accuracy: 0.2201\n",
            "Epoch 14/500\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 2.4554 - accuracy: 0.2296 - val_loss: 2.4840 - val_accuracy: 0.2372\n",
            "Epoch 15/500\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 2.4187 - accuracy: 0.2476 - val_loss: 2.4518 - val_accuracy: 0.2486\n",
            "Epoch 16/500\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 2.3772 - accuracy: 0.2652 - val_loss: 2.4176 - val_accuracy: 0.2713\n",
            "Epoch 17/500\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 2.3334 - accuracy: 0.2794 - val_loss: 2.3816 - val_accuracy: 0.2751\n",
            "Epoch 18/500\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 2.2864 - accuracy: 0.3008 - val_loss: 2.3439 - val_accuracy: 0.2865\n",
            "Epoch 19/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 2.2365 - accuracy: 0.3257 - val_loss: 2.3048 - val_accuracy: 0.3036\n",
            "Epoch 20/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 2.1853 - accuracy: 0.3546 - val_loss: 2.2637 - val_accuracy: 0.3150\n",
            "Epoch 21/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 2.1328 - accuracy: 0.3854 - val_loss: 2.2221 - val_accuracy: 0.3491\n",
            "Epoch 22/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 2.0783 - accuracy: 0.4179 - val_loss: 2.1788 - val_accuracy: 0.3643\n",
            "Epoch 23/500\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 2.0244 - accuracy: 0.4564 - val_loss: 2.1369 - val_accuracy: 0.3909\n",
            "Epoch 24/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 1.9694 - accuracy: 0.4922 - val_loss: 2.0938 - val_accuracy: 0.4137\n",
            "Epoch 25/500\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 1.9130 - accuracy: 0.5228 - val_loss: 2.0518 - val_accuracy: 0.4345\n",
            "Epoch 26/500\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 1.8580 - accuracy: 0.5605 - val_loss: 2.0087 - val_accuracy: 0.4573\n",
            "Epoch 27/500\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 1.8038 - accuracy: 0.5920 - val_loss: 1.9679 - val_accuracy: 0.4801\n",
            "Epoch 28/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 1.7512 - accuracy: 0.6188 - val_loss: 1.9265 - val_accuracy: 0.5161\n",
            "Epoch 29/500\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 1.6953 - accuracy: 0.6480 - val_loss: 1.8857 - val_accuracy: 0.5484\n",
            "Epoch 30/500\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 1.6437 - accuracy: 0.6663 - val_loss: 1.8475 - val_accuracy: 0.5750\n",
            "Epoch 31/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 1.5896 - accuracy: 0.6947 - val_loss: 1.8091 - val_accuracy: 0.5901\n",
            "Epoch 32/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 1.5380 - accuracy: 0.7154 - val_loss: 1.7713 - val_accuracy: 0.6072\n",
            "Epoch 33/500\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 1.4884 - accuracy: 0.7324 - val_loss: 1.7349 - val_accuracy: 0.6186\n",
            "Epoch 34/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 1.4406 - accuracy: 0.7455 - val_loss: 1.7006 - val_accuracy: 0.6357\n",
            "Epoch 35/500\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 1.3951 - accuracy: 0.7654 - val_loss: 1.6657 - val_accuracy: 0.6471\n",
            "Epoch 36/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 1.3490 - accuracy: 0.7787 - val_loss: 1.6320 - val_accuracy: 0.6584\n",
            "Epoch 37/500\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 1.3055 - accuracy: 0.7887 - val_loss: 1.6011 - val_accuracy: 0.6660\n",
            "Epoch 38/500\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 1.2647 - accuracy: 0.7974 - val_loss: 1.5690 - val_accuracy: 0.6736\n",
            "Epoch 39/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 1.2197 - accuracy: 0.8145 - val_loss: 1.5395 - val_accuracy: 0.6945\n",
            "Epoch 40/500\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 1.1811 - accuracy: 0.8150 - val_loss: 1.5109 - val_accuracy: 0.7040\n",
            "Epoch 41/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 1.1421 - accuracy: 0.8264 - val_loss: 1.4830 - val_accuracy: 0.7059\n",
            "Epoch 42/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 1.1035 - accuracy: 0.8323 - val_loss: 1.4567 - val_accuracy: 0.7135\n",
            "Epoch 43/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 1.0675 - accuracy: 0.8394 - val_loss: 1.4313 - val_accuracy: 0.7230\n",
            "Epoch 44/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 1.0320 - accuracy: 0.8468 - val_loss: 1.4061 - val_accuracy: 0.7230\n",
            "Epoch 45/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 1.0001 - accuracy: 0.8529 - val_loss: 1.3826 - val_accuracy: 0.7249\n",
            "Epoch 46/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.9686 - accuracy: 0.8541 - val_loss: 1.3606 - val_accuracy: 0.7324\n",
            "Epoch 47/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.9362 - accuracy: 0.8636 - val_loss: 1.3383 - val_accuracy: 0.7343\n",
            "Epoch 48/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.9055 - accuracy: 0.8674 - val_loss: 1.3172 - val_accuracy: 0.7362\n",
            "Epoch 49/500\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.8767 - accuracy: 0.8724 - val_loss: 1.2971 - val_accuracy: 0.7381\n",
            "Epoch 50/500\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.8504 - accuracy: 0.8767 - val_loss: 1.2775 - val_accuracy: 0.7476\n",
            "Epoch 51/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.8227 - accuracy: 0.8826 - val_loss: 1.2586 - val_accuracy: 0.7476\n",
            "Epoch 52/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.7959 - accuracy: 0.8821 - val_loss: 1.2411 - val_accuracy: 0.7476\n",
            "Epoch 53/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.7703 - accuracy: 0.8885 - val_loss: 1.2238 - val_accuracy: 0.7571\n",
            "Epoch 54/500\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.7470 - accuracy: 0.8907 - val_loss: 1.2070 - val_accuracy: 0.7571\n",
            "Epoch 55/500\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.7242 - accuracy: 0.9020 - val_loss: 1.1900 - val_accuracy: 0.7590\n",
            "Epoch 56/500\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.7011 - accuracy: 0.9035 - val_loss: 1.1749 - val_accuracy: 0.7609\n",
            "Epoch 57/500\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.6791 - accuracy: 0.9089 - val_loss: 1.1598 - val_accuracy: 0.7666\n",
            "Epoch 58/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.6570 - accuracy: 0.9146 - val_loss: 1.1457 - val_accuracy: 0.7685\n",
            "Epoch 59/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.6371 - accuracy: 0.9146 - val_loss: 1.1318 - val_accuracy: 0.7723\n",
            "Epoch 60/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.6175 - accuracy: 0.9208 - val_loss: 1.1176 - val_accuracy: 0.7742\n",
            "Epoch 61/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.5985 - accuracy: 0.9246 - val_loss: 1.1042 - val_accuracy: 0.7780\n",
            "Epoch 62/500\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.5791 - accuracy: 0.9279 - val_loss: 1.0919 - val_accuracy: 0.7799\n",
            "Epoch 63/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.5632 - accuracy: 0.9312 - val_loss: 1.0796 - val_accuracy: 0.7818\n",
            "Epoch 64/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.5455 - accuracy: 0.9345 - val_loss: 1.0681 - val_accuracy: 0.7837\n",
            "Epoch 65/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.5302 - accuracy: 0.9369 - val_loss: 1.0569 - val_accuracy: 0.7856\n",
            "Epoch 66/500\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.5127 - accuracy: 0.9395 - val_loss: 1.0454 - val_accuracy: 0.7875\n",
            "Epoch 67/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.4968 - accuracy: 0.9438 - val_loss: 1.0351 - val_accuracy: 0.7913\n",
            "Epoch 68/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.4813 - accuracy: 0.9457 - val_loss: 1.0247 - val_accuracy: 0.7913\n",
            "Epoch 69/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.4678 - accuracy: 0.9495 - val_loss: 1.0149 - val_accuracy: 0.7932\n",
            "Epoch 70/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.4542 - accuracy: 0.9514 - val_loss: 1.0056 - val_accuracy: 0.7932\n",
            "Epoch 71/500\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4404 - accuracy: 0.9542 - val_loss: 0.9957 - val_accuracy: 0.7932\n",
            "Epoch 72/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.4274 - accuracy: 0.9542 - val_loss: 0.9868 - val_accuracy: 0.7951\n",
            "Epoch 73/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.4141 - accuracy: 0.9583 - val_loss: 0.9783 - val_accuracy: 0.7951\n",
            "Epoch 74/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.4014 - accuracy: 0.9597 - val_loss: 0.9700 - val_accuracy: 0.7951\n",
            "Epoch 75/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.3893 - accuracy: 0.9630 - val_loss: 0.9620 - val_accuracy: 0.7970\n",
            "Epoch 76/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.3803 - accuracy: 0.9651 - val_loss: 0.9544 - val_accuracy: 0.7989\n",
            "Epoch 77/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.3676 - accuracy: 0.9658 - val_loss: 0.9470 - val_accuracy: 0.7970\n",
            "Epoch 78/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.3564 - accuracy: 0.9685 - val_loss: 0.9392 - val_accuracy: 0.8008\n",
            "Epoch 79/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.3458 - accuracy: 0.9706 - val_loss: 0.9321 - val_accuracy: 0.8027\n",
            "Epoch 80/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.3363 - accuracy: 0.9718 - val_loss: 0.9249 - val_accuracy: 0.8065\n",
            "Epoch 81/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.3274 - accuracy: 0.9722 - val_loss: 0.9191 - val_accuracy: 0.8065\n",
            "Epoch 82/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.3159 - accuracy: 0.9741 - val_loss: 0.9128 - val_accuracy: 0.8065\n",
            "Epoch 83/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.3076 - accuracy: 0.9758 - val_loss: 0.9059 - val_accuracy: 0.8083\n",
            "Epoch 84/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.2974 - accuracy: 0.9801 - val_loss: 0.8996 - val_accuracy: 0.8102\n",
            "Epoch 85/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.2884 - accuracy: 0.9806 - val_loss: 0.8946 - val_accuracy: 0.8083\n",
            "Epoch 86/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.2815 - accuracy: 0.9806 - val_loss: 0.8886 - val_accuracy: 0.8102\n",
            "Epoch 87/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.2724 - accuracy: 0.9824 - val_loss: 0.8822 - val_accuracy: 0.8102\n",
            "Epoch 88/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.2649 - accuracy: 0.9834 - val_loss: 0.8766 - val_accuracy: 0.8083\n",
            "Epoch 89/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.2565 - accuracy: 0.9841 - val_loss: 0.8722 - val_accuracy: 0.8121\n",
            "Epoch 90/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.2494 - accuracy: 0.9839 - val_loss: 0.8670 - val_accuracy: 0.8121\n",
            "Epoch 91/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.2419 - accuracy: 0.9848 - val_loss: 0.8622 - val_accuracy: 0.8102\n",
            "Epoch 92/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.2334 - accuracy: 0.9865 - val_loss: 0.8573 - val_accuracy: 0.8102\n",
            "Epoch 93/500\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.2270 - accuracy: 0.9877 - val_loss: 0.8530 - val_accuracy: 0.8102\n",
            "Epoch 94/500\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.2212 - accuracy: 0.9884 - val_loss: 0.8485 - val_accuracy: 0.8102\n",
            "Epoch 95/500\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.2141 - accuracy: 0.9881 - val_loss: 0.8438 - val_accuracy: 0.8102\n",
            "Epoch 96/500\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.2084 - accuracy: 0.9891 - val_loss: 0.8391 - val_accuracy: 0.8083\n",
            "Epoch 97/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.2016 - accuracy: 0.9893 - val_loss: 0.8350 - val_accuracy: 0.8083\n",
            "Epoch 98/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.1972 - accuracy: 0.9893 - val_loss: 0.8315 - val_accuracy: 0.8140\n",
            "Epoch 99/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.1911 - accuracy: 0.9900 - val_loss: 0.8275 - val_accuracy: 0.8140\n",
            "Epoch 100/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.1856 - accuracy: 0.9910 - val_loss: 0.8237 - val_accuracy: 0.8140\n",
            "Epoch 101/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.1802 - accuracy: 0.9903 - val_loss: 0.8195 - val_accuracy: 0.8121\n",
            "Epoch 102/500\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.1744 - accuracy: 0.9905 - val_loss: 0.8162 - val_accuracy: 0.8121\n",
            "Epoch 103/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.1695 - accuracy: 0.9922 - val_loss: 0.8132 - val_accuracy: 0.8121\n",
            "Epoch 104/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.1653 - accuracy: 0.9931 - val_loss: 0.8096 - val_accuracy: 0.8140\n",
            "Epoch 105/500\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.1600 - accuracy: 0.9938 - val_loss: 0.8065 - val_accuracy: 0.8140\n",
            "Epoch 106/500\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.1549 - accuracy: 0.9936 - val_loss: 0.8030 - val_accuracy: 0.8140\n",
            "Epoch 107/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.1512 - accuracy: 0.9941 - val_loss: 0.7998 - val_accuracy: 0.8159\n",
            "Epoch 108/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.1475 - accuracy: 0.9945 - val_loss: 0.7966 - val_accuracy: 0.8159\n",
            "Epoch 109/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.1425 - accuracy: 0.9945 - val_loss: 0.7935 - val_accuracy: 0.8159\n",
            "Epoch 110/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.1385 - accuracy: 0.9945 - val_loss: 0.7911 - val_accuracy: 0.8159\n",
            "Epoch 111/500\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.1347 - accuracy: 0.9950 - val_loss: 0.7882 - val_accuracy: 0.8140\n",
            "Epoch 112/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.1313 - accuracy: 0.9953 - val_loss: 0.7854 - val_accuracy: 0.8159\n",
            "Epoch 113/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.1275 - accuracy: 0.9953 - val_loss: 0.7832 - val_accuracy: 0.8159\n",
            "Epoch 114/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.1236 - accuracy: 0.9957 - val_loss: 0.7802 - val_accuracy: 0.8159\n",
            "Epoch 115/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.1198 - accuracy: 0.9957 - val_loss: 0.7782 - val_accuracy: 0.8159\n",
            "Epoch 116/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.1164 - accuracy: 0.9957 - val_loss: 0.7754 - val_accuracy: 0.8159\n",
            "Epoch 117/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.1130 - accuracy: 0.9962 - val_loss: 0.7732 - val_accuracy: 0.8159\n",
            "Epoch 118/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.1105 - accuracy: 0.9964 - val_loss: 0.7715 - val_accuracy: 0.8159\n",
            "Epoch 119/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.1076 - accuracy: 0.9957 - val_loss: 0.7690 - val_accuracy: 0.8159\n",
            "Epoch 120/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.1036 - accuracy: 0.9957 - val_loss: 0.7670 - val_accuracy: 0.8159\n",
            "Epoch 121/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.1009 - accuracy: 0.9962 - val_loss: 0.7654 - val_accuracy: 0.8178\n",
            "Epoch 122/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0982 - accuracy: 0.9969 - val_loss: 0.7627 - val_accuracy: 0.8178\n",
            "Epoch 123/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0948 - accuracy: 0.9972 - val_loss: 0.7610 - val_accuracy: 0.8178\n",
            "Epoch 124/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0926 - accuracy: 0.9972 - val_loss: 0.7591 - val_accuracy: 0.8197\n",
            "Epoch 125/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0899 - accuracy: 0.9964 - val_loss: 0.7579 - val_accuracy: 0.8178\n",
            "Epoch 126/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0877 - accuracy: 0.9974 - val_loss: 0.7556 - val_accuracy: 0.8178\n",
            "Epoch 127/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0859 - accuracy: 0.9969 - val_loss: 0.7549 - val_accuracy: 0.8216\n",
            "Epoch 128/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0829 - accuracy: 0.9976 - val_loss: 0.7522 - val_accuracy: 0.8159\n",
            "Epoch 129/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0803 - accuracy: 0.9979 - val_loss: 0.7512 - val_accuracy: 0.8197\n",
            "Epoch 130/500\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0783 - accuracy: 0.9979 - val_loss: 0.7496 - val_accuracy: 0.8178\n",
            "Epoch 131/500\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0763 - accuracy: 0.9981 - val_loss: 0.7480 - val_accuracy: 0.8197\n",
            "Epoch 132/500\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0738 - accuracy: 0.9979 - val_loss: 0.7475 - val_accuracy: 0.8197\n",
            "Epoch 133/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0724 - accuracy: 0.9981 - val_loss: 0.7452 - val_accuracy: 0.8178\n",
            "Epoch 134/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0704 - accuracy: 0.9976 - val_loss: 0.7441 - val_accuracy: 0.8235\n",
            "Epoch 135/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0682 - accuracy: 0.9976 - val_loss: 0.7435 - val_accuracy: 0.8216\n",
            "Epoch 136/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0660 - accuracy: 0.9991 - val_loss: 0.7413 - val_accuracy: 0.8235\n",
            "Epoch 137/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0649 - accuracy: 0.9983 - val_loss: 0.7409 - val_accuracy: 0.8235\n",
            "Epoch 138/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0622 - accuracy: 0.9995 - val_loss: 0.7394 - val_accuracy: 0.8235\n",
            "Epoch 139/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0612 - accuracy: 0.9988 - val_loss: 0.7380 - val_accuracy: 0.8235\n",
            "Epoch 140/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0594 - accuracy: 0.9991 - val_loss: 0.7373 - val_accuracy: 0.8235\n",
            "Epoch 141/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0575 - accuracy: 0.9991 - val_loss: 0.7364 - val_accuracy: 0.8235\n",
            "Epoch 142/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0568 - accuracy: 0.9993 - val_loss: 0.7356 - val_accuracy: 0.8235\n",
            "Epoch 143/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0548 - accuracy: 0.9993 - val_loss: 0.7347 - val_accuracy: 0.8235\n",
            "Epoch 144/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0532 - accuracy: 0.9993 - val_loss: 0.7334 - val_accuracy: 0.8235\n",
            "Epoch 145/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0521 - accuracy: 0.9995 - val_loss: 0.7324 - val_accuracy: 0.8235\n",
            "Epoch 146/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0503 - accuracy: 1.0000 - val_loss: 0.7315 - val_accuracy: 0.8235\n",
            "Epoch 147/500\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.0488 - accuracy: 0.9995 - val_loss: 0.7302 - val_accuracy: 0.8235\n",
            "Epoch 148/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0480 - accuracy: 0.9995 - val_loss: 0.7295 - val_accuracy: 0.8235\n",
            "Epoch 149/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0468 - accuracy: 1.0000 - val_loss: 0.7290 - val_accuracy: 0.8235\n",
            "Epoch 150/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0453 - accuracy: 1.0000 - val_loss: 0.7288 - val_accuracy: 0.8235\n",
            "Epoch 151/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0439 - accuracy: 0.9998 - val_loss: 0.7269 - val_accuracy: 0.8235\n",
            "Epoch 152/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0429 - accuracy: 1.0000 - val_loss: 0.7267 - val_accuracy: 0.8254\n",
            "Epoch 153/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0423 - accuracy: 1.0000 - val_loss: 0.7260 - val_accuracy: 0.8235\n",
            "Epoch 154/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0407 - accuracy: 1.0000 - val_loss: 0.7249 - val_accuracy: 0.8254\n",
            "Epoch 155/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0390 - accuracy: 1.0000 - val_loss: 0.7251 - val_accuracy: 0.8235\n",
            "Epoch 156/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0385 - accuracy: 0.9998 - val_loss: 0.7248 - val_accuracy: 0.8254\n",
            "Epoch 157/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0379 - accuracy: 1.0000 - val_loss: 0.7231 - val_accuracy: 0.8254\n",
            "Epoch 158/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0366 - accuracy: 1.0000 - val_loss: 0.7231 - val_accuracy: 0.8254\n",
            "Epoch 159/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0361 - accuracy: 1.0000 - val_loss: 0.7226 - val_accuracy: 0.8254\n",
            "Epoch 160/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0352 - accuracy: 1.0000 - val_loss: 0.7222 - val_accuracy: 0.8254\n",
            "Epoch 161/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0339 - accuracy: 1.0000 - val_loss: 0.7224 - val_accuracy: 0.8254\n",
            "Epoch 162/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0330 - accuracy: 1.0000 - val_loss: 0.7221 - val_accuracy: 0.8254\n",
            "Epoch 163/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0325 - accuracy: 1.0000 - val_loss: 0.7211 - val_accuracy: 0.8254\n",
            "Epoch 164/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0315 - accuracy: 1.0000 - val_loss: 0.7198 - val_accuracy: 0.8254\n",
            "Epoch 165/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0307 - accuracy: 1.0000 - val_loss: 0.7199 - val_accuracy: 0.8254\n",
            "Epoch 166/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0301 - accuracy: 0.9998 - val_loss: 0.7194 - val_accuracy: 0.8235\n",
            "Epoch 167/500\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0289 - accuracy: 1.0000 - val_loss: 0.7196 - val_accuracy: 0.8235\n",
            "Epoch 168/500\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0282 - accuracy: 1.0000 - val_loss: 0.7186 - val_accuracy: 0.8235\n",
            "Epoch 169/500\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0277 - accuracy: 1.0000 - val_loss: 0.7188 - val_accuracy: 0.8235\n",
            "Epoch 170/500\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0270 - accuracy: 1.0000 - val_loss: 0.7184 - val_accuracy: 0.8235\n",
            "Epoch 171/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0263 - accuracy: 1.0000 - val_loss: 0.7185 - val_accuracy: 0.8235\n",
            "Epoch 172/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0256 - accuracy: 1.0000 - val_loss: 0.7179 - val_accuracy: 0.8235\n",
            "Epoch 173/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0250 - accuracy: 1.0000 - val_loss: 0.7180 - val_accuracy: 0.8235\n",
            "Epoch 174/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0243 - accuracy: 1.0000 - val_loss: 0.7178 - val_accuracy: 0.8235\n",
            "Epoch 175/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0237 - accuracy: 1.0000 - val_loss: 0.7172 - val_accuracy: 0.8235\n",
            "Epoch 176/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0230 - accuracy: 1.0000 - val_loss: 0.7174 - val_accuracy: 0.8235\n",
            "Epoch 177/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0226 - accuracy: 1.0000 - val_loss: 0.7164 - val_accuracy: 0.8235\n",
            "Epoch 178/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0221 - accuracy: 1.0000 - val_loss: 0.7158 - val_accuracy: 0.8235\n",
            "Epoch 179/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0215 - accuracy: 1.0000 - val_loss: 0.7164 - val_accuracy: 0.8235\n",
            "Epoch 180/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0209 - accuracy: 1.0000 - val_loss: 0.7164 - val_accuracy: 0.8235\n",
            "Epoch 181/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0206 - accuracy: 1.0000 - val_loss: 0.7164 - val_accuracy: 0.8235\n",
            "Epoch 182/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0198 - accuracy: 1.0000 - val_loss: 0.7167 - val_accuracy: 0.8235\n",
            "Epoch 183/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0194 - accuracy: 1.0000 - val_loss: 0.7172 - val_accuracy: 0.8235\n",
            "Epoch 184/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0187 - accuracy: 1.0000 - val_loss: 0.7164 - val_accuracy: 0.8235\n",
            "Epoch 185/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0184 - accuracy: 1.0000 - val_loss: 0.7159 - val_accuracy: 0.8235\n",
            "Epoch 186/500\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.0180 - accuracy: 1.0000 - val_loss: 0.7155 - val_accuracy: 0.8235\n",
            "Epoch 187/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0179 - accuracy: 1.0000 - val_loss: 0.7160 - val_accuracy: 0.8235\n",
            "Epoch 188/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0172 - accuracy: 1.0000 - val_loss: 0.7163 - val_accuracy: 0.8235\n",
            "Epoch 189/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0167 - accuracy: 1.0000 - val_loss: 0.7166 - val_accuracy: 0.8235\n",
            "Epoch 190/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0166 - accuracy: 1.0000 - val_loss: 0.7155 - val_accuracy: 0.8235\n",
            "Epoch 191/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0158 - accuracy: 1.0000 - val_loss: 0.7159 - val_accuracy: 0.8235\n",
            "Epoch 192/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0156 - accuracy: 1.0000 - val_loss: 0.7161 - val_accuracy: 0.8235\n",
            "Epoch 193/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0154 - accuracy: 1.0000 - val_loss: 0.7168 - val_accuracy: 0.8235\n",
            "Epoch 194/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0148 - accuracy: 1.0000 - val_loss: 0.7162 - val_accuracy: 0.8235\n",
            "Epoch 195/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0144 - accuracy: 1.0000 - val_loss: 0.7166 - val_accuracy: 0.8235\n",
            "Epoch 196/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 0.7163 - val_accuracy: 0.8235\n",
            "Epoch 197/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 0.7156 - val_accuracy: 0.8216\n",
            "Epoch 198/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 0.7174 - val_accuracy: 0.8235\n",
            "Epoch 199/500\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 0.7160 - val_accuracy: 0.8235\n",
            "Epoch 200/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: 0.7158 - val_accuracy: 0.8235\n",
            "Epoch 201/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 0.7163 - val_accuracy: 0.8235\n",
            "Epoch 202/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 0.7154 - val_accuracy: 0.8235\n",
            "Epoch 203/500\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 0.7171 - val_accuracy: 0.8235\n",
            "Epoch 204/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 0.7159 - val_accuracy: 0.8235\n",
            "Epoch 205/500\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 0.7180 - val_accuracy: 0.8235\n",
            "Epoch 206/500\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 0.7167 - val_accuracy: 0.8216\n",
            "Epoch 207/500\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 0.7182 - val_accuracy: 0.8235\n",
            "Epoch 208/500\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 0.7180 - val_accuracy: 0.8235\n",
            "Epoch 209/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 0.7168 - val_accuracy: 0.8235\n",
            "Epoch 210/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.7181 - val_accuracy: 0.8216\n",
            "Epoch 211/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.7175 - val_accuracy: 0.8254\n",
            "Epoch 212/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.7185 - val_accuracy: 0.8235\n",
            "Epoch 213/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.7195 - val_accuracy: 0.8216\n",
            "Epoch 214/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.7191 - val_accuracy: 0.8197\n",
            "Epoch 215/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.7186 - val_accuracy: 0.8216\n",
            "Epoch 216/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.7186 - val_accuracy: 0.8235\n",
            "Epoch 217/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.7190 - val_accuracy: 0.8197\n",
            "Epoch 217: early stopping\n"
          ]
        }
      ],
      "source": [
        "# training the model\n",
        "epochs = 500\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
        "                                            patience=15,\n",
        "                                            verbose=1)\n",
        "history = model.fit(train_ds,\n",
        "                    validation_data=val_ds,\n",
        "                    epochs=epochs,\n",
        "                    callbacks=[callback])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Validation of the model"
      ],
      "metadata": {
        "id": "ky5q5SiimdpF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FksY9EwwHDkd",
        "outputId": "b48d8003-024d-4b09-b015-1f3ed3765ea6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6826 - accuracy: 0.8425\n",
            "Loss:  0.6826296448707581\n",
            "Accuracy:  0.8425047397613525\n"
          ]
        }
      ],
      "source": [
        "# printing loss and accuracy of the model on the test set\n",
        "loss, accuracy = model.evaluate(test_ds)\n",
        "print(\"Loss: \", loss)\n",
        "print(\"Accuracy: \", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "cPdyDruxHIv1",
        "outputId": "061dcf03-c958-4830-fcf9-9369eb3f75d4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "# extracting the history of training and its keys\n",
        "history_dict = history.history\n",
        "history_dict.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "shbF_xRlHDqZ"
      },
      "outputs": [],
      "source": [
        "acc = history_dict['accuracy']\n",
        "val_acc = history_dict['val_accuracy']\n",
        "loss = history_dict['loss']\n",
        "val_loss = history_dict['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "iLsoTgHGP7Oq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "outputId": "f6dae3b3-4b51-46fe-e289-2f1616428a45"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# ploting of loss\n",
        "plt.plot(epochs, loss, 'b', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "# plotting of accuracy\n",
        "plt.plot(epochs, acc, 'b', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "**Second one is a CNN model** with 0.8311195373535156 accuracy\n"
      ],
      "metadata": {
        "id": "Ykk8nS3go4ez"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model configuration\n",
        "embedding_dim = 4096\n",
        "num_of_labels = 20\n",
        "\n",
        "model_1 = tf.keras.Sequential([\n",
        "    layers.Embedding(max_features + 1, embedding_dim),\n",
        "    layers.Conv1D(32, 3, activation='relu'),\n",
        "    layers.MaxPooling1D(5),\n",
        "    layers.Dropout(0.15),\n",
        "    layers.Conv1D(64, 3, activation='relu'),\n",
        "    layers.GlobalMaxPooling1D(),\n",
        "    layers.Dropout(0.15),\n",
        "    layers.Dense(num_of_labels, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "mQpdSp9so9m0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model compilation\n",
        "model_1.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "# training the model\n",
        "epochs = 500\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
        "                                            patience=30,\n",
        "                                            verbose=1)\n",
        "history_1 = model_1.fit(train_ds,\n",
        "                    validation_data=val_ds,\n",
        "                    epochs=epochs,\n",
        "                    callbacks=[callback])"
      ],
      "metadata": {
        "id": "GrVG1SkLpb8E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# printing loss and accuracy of the model on the test set\n",
        "loss, accuracy = model_1.evaluate(test_ds)\n",
        "print(\"Loss: \", loss)\n",
        "print(\"Accuracy: \", accuracy)"
      ],
      "metadata": {
        "id": "lHvAxoFhqyk_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YQj61lIMvX-Y"
      },
      "outputs": [],
      "source": [
        "# creating the probability model for testing\n",
        "probability_model = tf.keras.Sequential([model_1, tf.keras.layers.Softmax()])\n",
        "\n",
        "# predicting test samples\n",
        "predictions = probability_model.predict(raw_test_batch.map(vectorize_text))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# extracting the history of training and its keys\n",
        "history_dict = history_1.history\n",
        "history_dict.keys()"
      ],
      "metadata": {
        "id": "K7ecnSu5qW3A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eFiMW-S_qG8_"
      },
      "outputs": [],
      "source": [
        "acc = history_dict['accuracy']\n",
        "val_acc = history_dict['val_accuracy']\n",
        "loss = history_dict['loss']\n",
        "val_loss = history_dict['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KODp0kqoqG9A"
      },
      "outputs": [],
      "source": [
        "# ploting of loss\n",
        "plt.plot(epochs, loss, 'b', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "# plotting of accuracy\n",
        "plt.plot(epochs, acc, 'b', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "**Genarete a model with Transformer block**\n"
      ],
      "metadata": {
        "id": "lv_YywOWt9x3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerBlock(layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.ffn = tf.keras.Sequential([\n",
        "            layers.Dense(ff_dim, activation=\"relu\"),\n",
        "            layers.Dense(embed_dim),\n",
        "        ])\n",
        "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = layers.Dropout(rate)\n",
        "        self.dropout2 = layers.Dropout(rate)\n",
        "\n",
        "    def call(self, inputs, training):\n",
        "        attn_output = self.att(inputs, inputs)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(inputs + attn_output)\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        return self.layernorm2(out1 + ffn_output)\n"
      ],
      "metadata": {
        "id": "5al0qMdQuIXe"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 128\n",
        "num_heads = 4\n",
        "ff_dim = 128\n",
        "dropout_rate = 0.20\n",
        "num_of_labels = 20\n",
        "\n",
        "inputs = layers.Input(shape=(309,))\n",
        "embedding_layer = layers.Embedding(max_features + 1, embedding_dim)(inputs)\n",
        "transformer_layer = TransformerBlock(embedding_dim, num_heads, ff_dim, dropout_rate)(embedding_layer)\n",
        "pooling_layer = layers.GlobalAveragePooling1D()(transformer_layer)\n",
        "dropout_layer = layers.Dropout(0.15)(pooling_layer)\n",
        "outputs = layers.Dense(num_of_labels, activation=\"softmax\")(dropout_layer)\n",
        "\n",
        "model_2 = tf.keras.Model(inputs=inputs, outputs=outputs)"
      ],
      "metadata": {
        "id": "v3FapF4WuKpu"
      },
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model compilation\n",
        "model_2.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "# training the model\n",
        "epochs = 500\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
        "                                            patience=30,\n",
        "                                            verbose=1)\n",
        "history_2 = model_2.fit(train_ds,\n",
        "                    validation_data=val_ds,\n",
        "                    epochs=epochs,\n",
        "                    callbacks=[callback])"
      ],
      "metadata": {
        "id": "cYLd7jBTue3v",
        "outputId": "f1e0c24d-5df3-4ac5-c64f-068ebcd84856",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/backend.py:5585: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
            "  output, from_logits = _get_logits(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "36/36 [==============================] - 9s 163ms/step - loss: 2.8739 - accuracy: 0.1426 - val_loss: 2.7141 - val_accuracy: 0.2011\n",
            "Epoch 2/500\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 2.7353 - accuracy: 0.1622 - val_loss: 2.6501 - val_accuracy: 0.2353\n",
            "Epoch 3/500\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 2.4933 - accuracy: 0.2645 - val_loss: 2.1325 - val_accuracy: 0.3378\n",
            "Epoch 4/500\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 1.2997 - accuracy: 0.6409 - val_loss: 1.0763 - val_accuracy: 0.7495\n",
            "Epoch 5/500\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.3049 - accuracy: 0.9229 - val_loss: 1.1252 - val_accuracy: 0.7875\n",
            "Epoch 6/500\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.0674 - accuracy: 0.9860 - val_loss: 1.1975 - val_accuracy: 0.7856\n",
            "Epoch 7/500\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.0177 - accuracy: 0.9974 - val_loss: 1.2412 - val_accuracy: 0.7818\n",
            "Epoch 8/500\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.0058 - accuracy: 0.9998 - val_loss: 1.2045 - val_accuracy: 0.7932\n",
            "Epoch 9/500\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.0036 - accuracy: 0.9998 - val_loss: 1.2205 - val_accuracy: 0.7970\n",
            "Epoch 10/500\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.2216 - val_accuracy: 0.7989\n",
            "Epoch 11/500\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.2316 - val_accuracy: 0.8008\n",
            "Epoch 12/500\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.2411 - val_accuracy: 0.8027\n",
            "Epoch 13/500\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.2502 - val_accuracy: 0.8027\n",
            "Epoch 14/500\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.2587 - val_accuracy: 0.8027\n",
            "Epoch 15/500\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.2664 - val_accuracy: 0.8065\n",
            "Epoch 16/500\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.2741 - val_accuracy: 0.8065\n",
            "Epoch 17/500\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 9.6766e-04 - accuracy: 1.0000 - val_loss: 1.2821 - val_accuracy: 0.8083\n",
            "Epoch 18/500\n",
            "36/36 [==============================] - 3s 94ms/step - loss: 8.6312e-04 - accuracy: 1.0000 - val_loss: 1.2896 - val_accuracy: 0.8065\n",
            "Epoch 19/500\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 7.9986e-04 - accuracy: 1.0000 - val_loss: 1.2967 - val_accuracy: 0.8083\n",
            "Epoch 20/500\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 7.6647e-04 - accuracy: 1.0000 - val_loss: 1.3036 - val_accuracy: 0.8083\n",
            "Epoch 21/500\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 6.8279e-04 - accuracy: 1.0000 - val_loss: 1.3095 - val_accuracy: 0.8083\n",
            "Epoch 22/500\n",
            "36/36 [==============================] - 3s 87ms/step - loss: 6.4978e-04 - accuracy: 1.0000 - val_loss: 1.3161 - val_accuracy: 0.8065\n",
            "Epoch 23/500\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 5.9955e-04 - accuracy: 1.0000 - val_loss: 1.3224 - val_accuracy: 0.8083\n",
            "Epoch 24/500\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 5.8379e-04 - accuracy: 1.0000 - val_loss: 1.3288 - val_accuracy: 0.8083\n",
            "Epoch 25/500\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 5.5174e-04 - accuracy: 1.0000 - val_loss: 1.3349 - val_accuracy: 0.8083\n",
            "Epoch 26/500\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 5.2070e-04 - accuracy: 1.0000 - val_loss: 1.3405 - val_accuracy: 0.8102\n",
            "Epoch 27/500\n",
            "36/36 [==============================] - 3s 90ms/step - loss: 4.8572e-04 - accuracy: 1.0000 - val_loss: 1.3461 - val_accuracy: 0.8102\n",
            "Epoch 28/500\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 4.4804e-04 - accuracy: 1.0000 - val_loss: 1.3512 - val_accuracy: 0.8102\n",
            "Epoch 29/500\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 4.2643e-04 - accuracy: 1.0000 - val_loss: 1.3560 - val_accuracy: 0.8102\n",
            "Epoch 30/500\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 3.9993e-04 - accuracy: 1.0000 - val_loss: 1.3608 - val_accuracy: 0.8102\n",
            "Epoch 31/500\n",
            "36/36 [==============================] - 3s 88ms/step - loss: 3.8972e-04 - accuracy: 1.0000 - val_loss: 1.3658 - val_accuracy: 0.8102\n",
            "Epoch 32/500\n",
            "36/36 [==============================] - 3s 91ms/step - loss: 3.6222e-04 - accuracy: 1.0000 - val_loss: 1.3698 - val_accuracy: 0.8083\n",
            "Epoch 33/500\n",
            "36/36 [==============================] - 3s 94ms/step - loss: 3.4215e-04 - accuracy: 1.0000 - val_loss: 1.3743 - val_accuracy: 0.8083\n",
            "Epoch 34/500\n",
            "36/36 [==============================] - 3s 93ms/step - loss: 3.2919e-04 - accuracy: 1.0000 - val_loss: 1.3786 - val_accuracy: 0.8083\n",
            "Epoch 34: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# printing loss and accuracy of the model on the test set\n",
        "loss, accuracy = model_2.evaluate(test_ds)\n",
        "print(\"Loss: \", loss)\n",
        "print(\"Accuracy: \", accuracy)"
      ],
      "metadata": {
        "id": "p6WXmc1GulzN",
        "outputId": "7c5871a7-43bd-471a-bd79-47a2d3eaca9d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 0s 38ms/step - loss: 1.3950 - accuracy: 0.8216\n",
            "Loss:  1.3950185775756836\n",
            "Accuracy:  0.8216318488121033\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5cbhBKR7NYPQ",
        "outputId": "7662d712-2ead-4f58-d701-3e8fc3a2ff21"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "execution_count": 86,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# showing the first test sample result label\n",
        "np.argmax(predictions[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNsnTWVuu3xj",
        "outputId": "658a983f-8653-4dc3-e7b4-1398f13b8818"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "text         herschel sulfur spring olive night reflective ...\n",
              "label                                           Luggage & Bags\n",
              "label_int                                                   12\n",
              "Name: 3686, dtype: object"
            ]
          },
          "execution_count": 87,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# showing the true label of the first test sample\n",
        "test_df.iloc[0]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U keras-tuner"
      ],
      "metadata": {
        "id": "YItRF2vK_Yt0",
        "outputId": "eeab725e-4101-4ff5-8632-b696f2450d22",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.3/167.3 KB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "**TUNING CNN Model**"
      ],
      "metadata": {
        "id": "iP4qQyuL-sEi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "from kerastuner.tuners import RandomSearch\n",
        "\n",
        "# Define hyperparameters\n",
        "embedding_dim = 128\n",
        "num_filters = 64\n",
        "kernel_size = 5\n",
        "dense_units = 128\n",
        "dropout_rate = 0.5\n",
        "max_features = 10000\n",
        "\n",
        "# Define the text vectorization layer\n",
        "vectorize_layer = TextVectorization(\n",
        "    max_tokens=max_features,\n",
        "    output_mode='int',\n",
        "    output_sequence_length=500)\n",
        "\n",
        "# Define the model builder function for hyperparameter tuning\n",
        "def build_model(hp):\n",
        "    # Define hyperparameters\n",
        "    embedding_dim = hp.Int('embedding_dim', min_value=3, max_value=4096, step=64)\n",
        "    num_filters = hp.Int('num_filters', min_value=32, max_value=128, step=4)\n",
        "    kernel_size = hp.Int('kernel_size', min_value=3, max_value=9, step=2)\n",
        "    dense_units = hp.Int('dense_units', min_value=64, max_value=256, step=64)\n",
        "    dropout_rate = hp.Float('dropout_rate', min_value=0.1, max_value=0.5, step=0.05)\n",
        "\n",
        "    # Define the model architecture\n",
        "    model_3 = keras.Sequential([\n",
        "        layers.Embedding(max_features+1, embedding_dim),\n",
        "        layers.Conv1D(num_filters, kernel_size, activation='relu'),\n",
        "        layers.MaxPooling1D(),\n",
        "        layers.Conv1D(num_filters, kernel_size, activation='relu'),\n",
        "        layers.GlobalMaxPooling1D(),\n",
        "        layers.Dropout(dropout_rate),\n",
        "        layers.Dense(20)\n",
        "    ])\n",
        "\n",
        "    # Compile the model\n",
        "    model_3.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    return model_3\n",
        "\n",
        "# Instantiate the tuner\n",
        "tuner = RandomSearch(\n",
        "    build_model,\n",
        "    objective='val_accuracy',\n",
        "    max_trials=20,\n",
        "    executions_per_trial=1,\n",
        "    directory='my_dir',\n",
        "    project_name='my_project')\n",
        "\n",
        "# Fit the tuner to the data\n",
        "tuner.search(train_ds,\n",
        "             validation_data=val_ds,\n",
        "             epochs=400,\n",
        "             callbacks=[tf.keras.callbacks.EarlyStopping(\n",
        "                        monitor='val_loss', patience=10)])\n",
        "\n",
        "# Get the best model\n",
        "best_model = tuner.get_best_models(num_models=1)[0]"
      ],
      "metadata": {
        "id": "lH5WY_cn-rnV",
        "outputId": "b0231100-86cf-4367-dd57-ba984efe77a7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 20 Complete [00h 01m 28s]\n",
            "val_accuracy: 0.7874763011932373\n",
            "\n",
            "Best val_accuracy So Far: 0.8121442198753357\n",
            "Total elapsed time: 00h 18m 13s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {
        "id": "bOt2UPu7NbUW",
        "outputId": "d6fc48f2-9631-4ac2-ed15-b47e4f5b511f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "36/36 [==============================] - 10s 235ms/step - loss: 0.0116 - accuracy: 0.9969 - val_loss: 1.0554 - val_accuracy: 0.7856\n",
            "Epoch 2/500\n",
            "36/36 [==============================] - 4s 114ms/step - loss: 0.0117 - accuracy: 0.9972 - val_loss: 1.0753 - val_accuracy: 0.7951\n",
            "Epoch 3/500\n",
            "36/36 [==============================] - 4s 112ms/step - loss: 0.0063 - accuracy: 0.9988 - val_loss: 1.1236 - val_accuracy: 0.8008\n",
            "Epoch 4/500\n",
            "36/36 [==============================] - 4s 117ms/step - loss: 0.0064 - accuracy: 0.9983 - val_loss: 1.1332 - val_accuracy: 0.7970\n",
            "Epoch 5/500\n",
            "36/36 [==============================] - 4s 110ms/step - loss: 0.0087 - accuracy: 0.9983 - val_loss: 1.1517 - val_accuracy: 0.7932\n",
            "Epoch 6/500\n",
            "36/36 [==============================] - 4s 106ms/step - loss: 0.0054 - accuracy: 0.9986 - val_loss: 1.1589 - val_accuracy: 0.8140\n",
            "Epoch 7/500\n",
            "36/36 [==============================] - 4s 106ms/step - loss: 0.0043 - accuracy: 0.9991 - val_loss: 1.2679 - val_accuracy: 0.7932\n",
            "Epoch 8/500\n",
            "36/36 [==============================] - 4s 107ms/step - loss: 0.0040 - accuracy: 0.9993 - val_loss: 1.2096 - val_accuracy: 0.8140\n",
            "Epoch 9/500\n",
            "36/36 [==============================] - 4s 107ms/step - loss: 0.0063 - accuracy: 0.9988 - val_loss: 1.2938 - val_accuracy: 0.7913\n",
            "Epoch 10/500\n",
            "36/36 [==============================] - 4s 106ms/step - loss: 0.0049 - accuracy: 0.9991 - val_loss: 1.2954 - val_accuracy: 0.7989\n",
            "Epoch 11/500\n",
            "36/36 [==============================] - 4s 105ms/step - loss: 0.0036 - accuracy: 0.9993 - val_loss: 1.3038 - val_accuracy: 0.8065\n",
            "Epoch 12/500\n",
            "36/36 [==============================] - 4s 111ms/step - loss: 0.0051 - accuracy: 0.9988 - val_loss: 1.3661 - val_accuracy: 0.7989\n",
            "Epoch 13/500\n",
            "36/36 [==============================] - 4s 105ms/step - loss: 0.0034 - accuracy: 0.9995 - val_loss: 1.3649 - val_accuracy: 0.8008\n",
            "Epoch 14/500\n",
            "36/36 [==============================] - 4s 105ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.3528 - val_accuracy: 0.8140\n",
            "Epoch 15/500\n",
            "36/36 [==============================] - 4s 106ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.3851 - val_accuracy: 0.8046\n",
            "Epoch 16/500\n",
            "36/36 [==============================] - 4s 105ms/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 1.4151 - val_accuracy: 0.8065\n",
            "Epoch 17/500\n",
            "36/36 [==============================] - 4s 104ms/step - loss: 0.0043 - accuracy: 0.9993 - val_loss: 1.3445 - val_accuracy: 0.8140\n",
            "Epoch 18/500\n",
            "36/36 [==============================] - 4s 106ms/step - loss: 0.0026 - accuracy: 0.9993 - val_loss: 1.3443 - val_accuracy: 0.7989\n",
            "Epoch 19/500\n",
            "36/36 [==============================] - 4s 107ms/step - loss: 0.0042 - accuracy: 0.9988 - val_loss: 1.3765 - val_accuracy: 0.8102\n",
            "Epoch 20/500\n",
            "36/36 [==============================] - 4s 106ms/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 1.3867 - val_accuracy: 0.8008\n",
            "Epoch 21/500\n",
            "36/36 [==============================] - 4s 106ms/step - loss: 0.0035 - accuracy: 0.9991 - val_loss: 1.4051 - val_accuracy: 0.8065\n",
            "Epoch 22/500\n",
            "36/36 [==============================] - 4s 104ms/step - loss: 0.0037 - accuracy: 0.9983 - val_loss: 1.4749 - val_accuracy: 0.7875\n",
            "Epoch 23/500\n",
            "36/36 [==============================] - 4s 105ms/step - loss: 0.0035 - accuracy: 0.9986 - val_loss: 1.5376 - val_accuracy: 0.7894\n",
            "Epoch 24/500\n",
            "36/36 [==============================] - 4s 109ms/step - loss: 0.0041 - accuracy: 0.9991 - val_loss: 1.5602 - val_accuracy: 0.7799\n",
            "Epoch 25/500\n",
            "36/36 [==============================] - 4s 106ms/step - loss: 0.0064 - accuracy: 0.9986 - val_loss: 1.6592 - val_accuracy: 0.7856\n",
            "Epoch 26/500\n",
            "36/36 [==============================] - 4s 105ms/step - loss: 0.0072 - accuracy: 0.9983 - val_loss: 1.6154 - val_accuracy: 0.7761\n",
            "Epoch 27/500\n",
            "36/36 [==============================] - 4s 105ms/step - loss: 0.0029 - accuracy: 0.9993 - val_loss: 1.7929 - val_accuracy: 0.7761\n",
            "Epoch 28/500\n",
            "36/36 [==============================] - 4s 106ms/step - loss: 0.0070 - accuracy: 0.9979 - val_loss: 1.5566 - val_accuracy: 0.7913\n",
            "Epoch 29/500\n",
            "36/36 [==============================] - 4s 105ms/step - loss: 0.0129 - accuracy: 0.9964 - val_loss: 1.6679 - val_accuracy: 0.7837\n",
            "Epoch 30/500\n",
            "36/36 [==============================] - 4s 104ms/step - loss: 0.0047 - accuracy: 0.9986 - val_loss: 1.8426 - val_accuracy: 0.7647\n",
            "Epoch 31/500\n",
            "36/36 [==============================] - 4s 105ms/step - loss: 0.0102 - accuracy: 0.9960 - val_loss: 1.8741 - val_accuracy: 0.7799\n",
            "Epoch 31: early stopping\n"
          ]
        }
      ],
      "source": [
        "# model compilation\n",
        "best_model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "# training the model\n",
        "epochs = 500\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
        "                                            patience=30,\n",
        "                                            verbose=1)\n",
        "best_model = best_model.fit(train_ds,\n",
        "                    validation_data=val_ds,\n",
        "                    epochs=epochs,\n",
        "                    callbacks=[callback])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " # printing loss and accuracy of the model on the test set\n",
        "loss, accuracy = best_model.evaluate(test_ds)\n",
        "print(\"Loss: \", loss)\n",
        "print(\"Accuracy: \", accuracy)"
      ],
      "metadata": {
        "id": "64DIpuXAkZz4",
        "outputId": "9fc358ab-c9b2-4398-dd9a-4b86a66f919a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        }
      },
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-156-ff3d3d9b3c57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# printing loss and accuracy of the model on the test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loss: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'History' object has no attribute 'evaluate'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OVD8BOB6nWbb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CSw7kwIQipyc"
      },
      "source": [
        "**Author:** https://Aliejabbari.github.io/"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}